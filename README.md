# Mobile-Robotics
## [PS1](Mobile-Robotics/ps1/): First-Order Covariance Propagation
In this task, we discussed about the linearization error we met during the SLAM procedure. Often the linearization process is required for that some of the filter could only operated linearized and Gaussian system. 
I first generate a point cloud representing 10,000 samples form the distribution over the position of the object as measured sensor frame (i.e. r,<img src="https://render.githubusercontent.com/render/math?math=\theta">) and the Cartesian (x,y) coordinate frame. It was generated by utilizing <img src="https://render.githubusercontent.com/render/math?math=\mu"> + <img src="https://render.githubusercontent.com/render/math?math=\sigma*randn">. 

As shown in the following picture, since the analytical Cartesian frame is the frame being linearized, the red(calculated covariance and mean) and blue(sampled covariance and mean) ellipse wouldnâ€™t match. It would lose some information when linearization. 

<img src="ps1/pic/Sensor_Cartesian Frame.png" width="600" >

This question utilized different covariance matrix with <img src="https://render.githubusercontent.com/render/math?math=\rho_{r\theta} = 0.1,\  0.5,\  0.9"> to plot the sensor frame and cartesian frame. Covariance values were then calculated:

<img src="https://render.githubusercontent.com/render/math?math=\sigma_{r\theta} = \rho_{r\theta}\times\sigma_x\sigma_y">.

Also, we could draw the sample with the following equations:

<img src="https://render.githubusercontent.com/render/math?math=\sigma_{r\theta} =Z = LX+\mu">

X is just another random value and <img src="https://render.githubusercontent.com/render/math?math=\sigma_{r\theta} =\Sigma = LL^T">. By plugging in the L value, we could produce new data point and plot as the new Sensor Frame in the above figure. The data is no longer independent within their two coordinates. When transformed by Jacobian, the sample-based covariance contours are being off with the calculated contours. As long as the correlation value gets bigger, the red and blue contour differs even further. 

<img src="ps1/pic/3_F.jpg" width="700" >


## [PS2](Mobile-Robotics/ps2/): Filters and Propagation
This homework is meant to deal with extented kalman filter(EKF), unscented kalman (UKF), and particle filter(PF).
| EKF | UKF | PF |
| :---: |:---:| :---:|
| ![EKF](ps2/Video/EKF_video.gif)  | ![UKF](ps2/Video/UKF_video.gif) | ![PF](ps2/Video/PF_video.gif)  |


## [PS3](Mobile-Robotics/ps3/) : Senor Model
In this task, both discrete and continuous sensor models for occupancy grid maps and semantic grid maps are implemented. Also, it is then evaluated with [Intel dataset](https://lucacarlone.mit.edu/datasets/).
